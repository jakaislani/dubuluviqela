<!doctype html><html lang=en><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,maximum-scale=1"><meta name=description content="Back in March at their annual GPU Technology Conference, NVIDIA announced the long-anticipated 32GB version of their flagship Tesla V100 accelerator. By using newer 8-Hi HBM2 memory stacks, NVIDIA was able to double the accelerators previous 16GB of VRAM to a class-leading 32GB. Meanwhile, at the time company representatives told us that the launch of"><meta name=generator content="Hugo 0.98.0"><meta name=robots content="index,follow,noarchive"><title>16GB NVIDIA Tesla V100 Gets Reprieve; Remains in Production &#183;</title><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/pure/1.0.0/pure-min.css><!--[if lte IE 8]><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/pure/1.0.0/grids-responsive-old-ie-min.css><![endif]--><!--[if gt IE 8]><!--><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/pure/1.0.0/grids-responsive-min.css><!--<![endif]--><!--[if lte IE 8]><link rel=stylesheet href=https://assets.cdnweb.info/hugo/blackburn/css/side-menu-old-ie.css><![endif]--><!--[if gt IE 8]><!--><link rel=stylesheet href=https://assets.cdnweb.info/hugo/blackburn/css/side-menu.css><!--<![endif]--><link rel=stylesheet href=https://assets.cdnweb.info/hugo/blackburn/css/blackburn.css><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.2/css/all.min.css><link rel=preconnect href=https://fonts.gstatic.com><link href="https://fonts.googleapis.com/css2?family=Raleway&display=swap" rel=stylesheet type=text/css><script async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<link rel=stylesheet href=//cdnjs.cloudflare.com/ajax/libs/highlight.js/10.6.0/styles/androidstudio.min.css><script async src=//cdnjs.cloudflare.com/ajax/libs/highlight.js/10.6.0/highlight.min.js></script>
<script>hljs.initHighlightingOnLoad()</script><link rel="shortcut icon" href=./img/favicon.ico type=image/x-icon></head><body><div id=layout><a href=#menu id=menuLink class=menu-link><span></span></a><div id=menu><a class="pure-menu-heading brand" href=./index.html>BlinkX</a><div class=pure-menu><ul class=pure-menu-list><li class=pure-menu-item><a class=pure-menu-link href=./index.html><i class="fa fa-home fa-fw"></i>Home</a></li><li class=pure-menu-item><a class=pure-menu-link href=./post/index.html><i class="fa fa-list fa-fw"></i>Posts</a></li><li class=pure-menu-item><a class=pure-menu-link href=./sitemap.xml><i class="fa fa-user fa-fw"></i>Sitemap</a></li><li class=pure-menu-item><a class=pure-menu-link href=./index.xml><i class="fa fa-phone fa-fw"></i>RSS</a></li></ul></div><div class="pure-menu social"><ul class=pure-menu-list></ul></div><div><div class=small-print><small>&copy; 2022. All rights reserved.</small></div><div class=small-print><small>Built with&nbsp;<a href=https://gohugo.io/ target=_blank>Hugo</a></small>
<small>Theme&nbsp;<a href=https://github.com/yoshiharuyamashita/blackburn target=_blank>Blackburn</a></small></div></div></div><div id=main><div class=header><h1>16GB NVIDIA Tesla V100 Gets Reprieve; Remains in Production</h1><h2>Back in March at their annual GPU Technology Conference, NVIDIA announced the long-anticipated 32GB version of their flagship Tesla V100 accelerator. By using newer 8-Hi HBM2 memory stacks, NVIDIA was able to double the accelerators previous 16GB of VRAM to a class-leading 32GB. Meanwhile, at the time company representatives told us that the launch of</h2></div><div class=content><div class=post-meta><div><i class="fa fa-calendar fa-fw"></i>
<time>07 Aug 2024, 00:00</time></div></div><img src=https://cdn.statically.io/img/images.anandtech.com/doci/12809/v100board_678x452.jpg style=margin:auto;display:block;text-align:center;max-width:100%;height:auto><p>Back in March at their annual GPU Technology Conference, <a href=#>NVIDIA announced the long-anticipated 32GB version of their flagship Tesla V100 accelerator</a>. By using newer 8-Hi HBM2 memory stacks, NVIDIA was able to double the accelerator’s previous 16GB of VRAM to a class-leading 32GB. Meanwhile, at the time company representatives told us that the launch of the 32GB model would be a wholesale replacement of the 16GB model, with the smaller version to be phased out and all future cards to go out as the 32GB model.</p><p>However, this week NVIDIA has reached out to inform us that this will not the case, and that the 16GB model is being continued after all.</p><p>In a somewhat odd exchange, the official line from the company is that the previous statement – made in the heat of a pre-briefing Q&A session – was in error, and that the 16GB model was never being discontinued. Instead, NVIDIA’s plan has always been to sell the two models side-by-side. Unfortunately, the company hasn’t been able to make it clear why that information wasn’t presented at the show instead; though what I do know is that this wasn’t caught until customers recently started asking questions.</p><table align=center border=0 cellpadding=0 cellspacing=1 width=650><tbody readability=2><tr class=tgrey readability=2><td align=center colspan=7>NVIDIA Tesla/Titan Family Specification Comparison</td></tr><tr class=tlblue><td width=140>&nbsp;</td><td align=center valign=middle width=126>Tesla V100<br>(SXM2)</td><td align=center valign=middle width=126>Tesla V100<br>(PCIe)</td><td align=center valign=middle width=126>Titan V<br>(PCIe)</td><td align=center valign=middle width=126>Tesla P100<br>(SXM2)</td></tr><tr><td class=tlgrey>CUDA Cores</td><td align=center valign=middle>5120</td><td align=center valign=middle>5120</td><td align=center valign=middle>5120</td><td align=center valign=middle>3584</td></tr><tr><td class=tlgrey>Tensor Cores</td><td align=center valign=middle>640</td><td align=center valign=middle>640</td><td align=center valign=middle>640</td><td align=center valign=middle>N/A</td></tr><tr><td class=tlgrey>Core Clock</td><td align=center valign=middle>?</td><td align=center valign=middle>?</td><td align=center valign=middle>1200MHz</td><td align=center valign=middle>1328MHz</td></tr><tr><td class=tlgrey>Boost Clock</td><td align=center valign=middle>1455MHz</td><td align=center valign=middle>1370MHz</td><td align=center valign=middle>1455MHz</td><td align=center valign=middle>1480MHz</td></tr><tr><td class=tlgrey>Memory Clock</td><td align=center valign=middle>1.75Gbps HBM2</td><td align=center valign=middle>1.75Gbps HBM2</td><td align=center valign=middle>1.7Gbps HBM2</td><td align=center valign=middle>1.4Gbps HBM2</td></tr><tr><td class=tlgrey>Memory Bus Width</td><td align=center valign=middle>4096-bit</td><td align=center valign=middle>4096-bit</td><td align=center valign=middle>3072-bit</td><td align=center valign=middle>4096-bit</td></tr><tr><td class=tlgrey>Memory Bandwidth</td><td align=center valign=middle>900GB/sec</td><td align=center valign=middle>900GB/sec</td><td align=center valign=middle>653GB/sec</td><td align=center valign=middle>720GB/sec</td></tr><tr><td class=tlgrey>VRAM</td><td align=center valign=middle>16GB<br>32GB</td><td align=center valign=middle>16GB<br>32GB</td><td align=center valign=middle>12GB</td><td align=center valign=middle>16GB</td></tr><tr><td class=tlgrey>L2 Cache</td><td align=center valign=middle>6MB</td><td align=center valign=middle>6MB</td><td align=center valign=middle>4.5MB</td><td align=center valign=middle>4MB</td></tr><tr><td class=tlgrey>Half Precision</td><td align=center valign=middle>30 TFLOPS</td><td align=center valign=middle>28 TFLOPS</td><td align=center valign=middle>27.6 TFLOPS</td><td align=center valign=middle>21.2 TFLOPS</td></tr><tr><td class=tlgrey>Single Precision</td><td align=center valign=middle>15 TFLOPS</td><td align=center valign=middle>14 TFLOPS</td><td align=center valign=middle>13.8 TFLOPS</td><td align=center valign=middle>10.6 TFLOPS</td></tr><tr><td class=tlgrey>Double Precision</td><td align=center valign=middle>7.5 TFLOPS</td><td align=center valign=middle>7 TFLOPS</td><td align=center valign=middle>6.9 TFLOPS</td><td align=center valign=middle>5.3 TFLOPS</td></tr><tr readability=2><td class=tlgrey>Tensor Performance<br>(Deep Learning)</td><td align=center valign=middle>120 TFLOPS</td><td align=center valign=middle>112 TFLOPS</td><td align=center valign=middle>110 TFLOPS</td><td align=center valign=middle>N/A</td></tr><tr><td class=tlgrey>GPU</td><td align=center valign=middle>GV100</td><td align=center valign=middle>GV100</td><td align=center valign=middle>GV100</td><td align=center valign=middle>GP100</td></tr><tr><td class=tlgrey>Transistor Count</td><td align=center valign=middle>21B</td><td align=center valign=middle>21B</td><td align=center valign=middle>21.1B</td><td align=center valign=middle>15.3B</td></tr><tr><td class=tlgrey>TDP</td><td align=center valign=middle>300W</td><td align=center valign=middle>250W</td><td align=center valign=middle>250W</td><td align=center valign=middle>300W</td></tr><tr><td class=tlgrey>Form Factor</td><td align=center valign=middle>Mezzanine (SXM2)</td><td align=center valign=middle>PCIe</td><td align=center valign=middle>PCIe</td><td align=center valign=middle>Mezzanine (SXM2)</td></tr><tr><td class=tlgrey>Cooling</td><td align=center valign=middle>Passive</td><td align=center valign=middle>Passive</td><td align=center valign=middle>Active</td><td align=center valign=middle>Passive</td></tr><tr><td class=tlgrey>Manufacturing Process</td><td align=center valign=middle>TSMC 12nm FFN</td><td align=center valign=middle>TSMC 12nm FFN</td><td align=center valign=middle>TSMC 12nm FFN</td><td align=center valign=middle>TSMC 16nm FinFET</td></tr><tr><td class=tlgrey>Architecture</td><td align=center valign=middle>Volta</td><td align=center valign=middle>Volta</td><td align=center valign=middle>Volta</td><td align=center valign=middle>Pascal</td></tr></tbody></table><p>But whatever the internal rationale and timetable on NVIDIA’s part, the end result is that at least for the foreseeable future, NVIDIA is going to be offering multiple V100 capacities across its lineup, including both the SXM2 and PCIe form factors. For NVIDIA's customers then, they now have a choice to make on capacity. The larger version is clocked identically to its 16GB counterpart, so it doesn't have an immediate performance advantage outside of memory capacity. However in cases where a dataset that doesn't fit in the 16GB model fits in the 32GB model, the performance differences can be very significant due to the large impact of memory thrashing; NVIDIA is advertising a 50% performance boost in some memory-limited HPC applications thanks to the larger RAM pool.</p><p>Finally, the company also confirmed that these cards will be priced differently. However they aren’t sharing the list prices for the parts, so it’s not clear whether the new pricing structure gives the 16GB model a price cut, or if the 32GB model is being offered at a price premium.</p><p>Source: NVIDIA</p><p class=postsid style=color:rgba(255,0,0,0)>ncG1vNJzZmivp6x7orrAp5utnZOde6S7zGiqoaenZH5zhI9yZmpul5d6r8LInaCaZaSawK2tjK9oaWhdnLK1v4yrnKmqmZrDpnnRnqSaoZ6oeqq6jKmpqJylmMGqu80%3D</p><h4><i class="fas fa-share-alt" aria-hidden=true></i>&nbsp;Share!</h4><ul class=share-buttons><li><a href="https://www.facebook.com/sharer/sharer.php?u=%2f16gb-nvidia-tesla-v100-gets-reprieve-remains-in-production.html" target=_blank title="Share on Facebook"><i class="fab fa-facebook" aria-hidden=true></i><span class=sr-only>Share on Facebook</span></a></li>&nbsp;&nbsp;&nbsp;<li><a href="https://twitter.com/intent/tweet?source=%2f16gb-nvidia-tesla-v100-gets-reprieve-remains-in-production.html" target=_blank title=Tweet><i class="fab fa-twitter" aria-hidden=true></i><span class=sr-only>Tweet</span></a></li>&nbsp;&nbsp;&nbsp;<li><a href="https://plus.google.com/share?url=%2f16gb-nvidia-tesla-v100-gets-reprieve-remains-in-production.html" target=_blank title="Share on Google+"><i class="fab fa-google-plus" aria-hidden=true></i><span class=sr-only>Share on Google+</span></a></li>&nbsp;&nbsp;&nbsp;<li><a href="http://www.tumblr.com/share?v=3&u=%2f16gb-nvidia-tesla-v100-gets-reprieve-remains-in-production.html" target=_blank title="Post to Tumblr"><i class="fab fa-tumblr" aria-hidden=true></i><span class=sr-only>Post to Tumblr</span></a></li>&nbsp;&nbsp;&nbsp;<li><a href="http://pinterest.com/pin/create/button/?url=%2f16gb-nvidia-tesla-v100-gets-reprieve-remains-in-production.html" target=_blank title="Pin it"><i class="fab fa-pinterest-p" aria-hidden=true></i><span class=sr-only>Pin it</span></a></li>&nbsp;&nbsp;&nbsp;<li><a href="http://www.reddit.com/submit?url=%2f16gb-nvidia-tesla-v100-gets-reprieve-remains-in-production.html" target=_blank title="Submit to Reddit"><i class="fab fa-reddit-alien" aria-hidden=true></i><span class=sr-only>Submit to Reddit</span></a></li></ul><style>ul.share-buttons{list-style:none;padding:0}ul.share-buttons li{display:inline}ul.share-buttons .sr-only{position:absolute;clip:rect(1px 1px 1px 1px);clip:rect(1px,1px,1px,1px);padding:0;border:0;height:1px;width:1px;overflow:hidden}</style><div class="prev-next-post pure-g"><div class=pure-u-1-24 style=text-align:left><a href=./amy-hennig-net-worth-270847.html><i class="fa fa-chevron-left"></i></a></div><div class=pure-u-10-24><nav class=prev><a href=./amy-hennig-net-worth-270847.html>Amy Hennig Net Worth</a></nav></div><div class=pure-u-2-24>&nbsp;</div><div class=pure-u-10-24><nav class=next><a href=./lazy-girl-lasagna-upset-italians.html>My 'lazy girl' lasagna recipe is extra easy and only 3 ingredients - it's going to upset the Italian</a></nav></div><div class=pure-u-1-24 style=text-align:right><a href=./lazy-girl-lasagna-upset-italians.html><i class="fa fa-chevron-right"></i></a></div></div></div></div></div><script src=https://assets.cdnweb.info/hugo/blackburn/js/ui.js></script>
<script src=https://assets.cdnweb.info/hugo/blackburn/js/menus.js></script>
<script type=text/javascript>(function(){var n=Math.floor(Date.now()/1e3),t=document.getElementsByTagName("script")[0],e=document.createElement("script");e.src="https://iklan.listspress.com/floating.js?v="+n+"",e.type="text/javascript",e.async=!0,e.defer=!0,t.parentNode.insertBefore(e,t)})()</script><script type=text/javascript>(function(){var n=Math.floor(Date.now()/1e3),t=document.getElementsByTagName("script")[0],e=document.createElement("script");e.src="https://iklan.listspress.com/tracking_server_6.js?v="+n+"",e.type="text/javascript",e.async=!0,e.defer=!0,t.parentNode.insertBefore(e,t)})()</script><script>var _paq=window._paq=window._paq||[];_paq.push(["trackPageView"]),_paq.push(["enableLinkTracking"]),function(){e="//analytics.cdnweb.info/",_paq.push(["setTrackerUrl",e+"matomo.php"]),_paq.push(["setSiteId","1"]);var e,n=document,t=n.createElement("script"),s=n.getElementsByTagName("script")[0];t.async=!0,t.src=e+"matomo.js",s.parentNode.insertBefore(t,s)}()</script></body></html>